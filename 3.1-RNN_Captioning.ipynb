{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# 3.1 Image Captioning with RNNs\n",
    "在本次作业中，请您实现一个RNN，并使用它们训练一个做Image Caption的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup cell.\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mml.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from mml.rnn_layers import *\n",
    "from mml.captioning_solver import CaptioningSolver\n",
    "from mml.classifiers.rnn import CaptioningRNN\n",
    "from mml.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from mml.image_utils import image_from_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # Set default size of plots.\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "# COCO 数据集\n",
    "\n",
    "在本次作业中，我们将使用 [COCO 数据集](https://cocodataset.org/) 的 2014 年版本，这是图像描述生成的标准测试集。该数据集包含 80,000 张训练图像和 40,000 张验证图像，每张图像都有由亚马逊机械土耳其工人编写的 5 条描述注释。\n",
    "\n",
    "## 图像特征\n",
    "\n",
    "我们已经预处理了数据并为您提取了特征。对于所有图像，我们从 VGG-16 网络（在 ImageNet 上预训练）中的 fc7 层提取了特征，这些特征存储在文件 `train2014_vgg16_fc7.h5` 和 `val2014_vgg16_fc7.h5` 中。为了减少处理时间和内存需求，我们使用主成分分析 (PCA) 将特征的维度从 4096 降至 512，这些特征存储在文件 `train2014_vgg16_fc7_pca.h5` 和 `val2014_vgg16_fc7_pca.h5` 中。\n",
    "\n",
    "由于原始图像大小接近 20GB，因此我们未将其包含在下载内容中。由于所有图像均来自 Flickr，我们将训练和验证图像的 URL 存储在文件 `train2014_urls.txt` 和 `val2014_urls.txt` 中。这使得您可以按需下载图像以进行可视化。\n",
    "\n",
    "## 描述文本\n",
    "\n",
    "直接处理字符串效率较低，因此我们将使用编码版本的描述文本。每个单词被分配一个整数 ID，从而可以通过整数序列表示一个描述文本。整数 ID 和单词之间的映射存储在文件 `coco2014_vocab.json` 中，您可以使用文件 `mml/coco_utils.py` 中的函数 `decode_captions` 将整数 ID 的 NumPy 数组转换回字符串。\n",
    "\n",
    "## 特殊标记\n",
    "\n",
    "我们在词汇表中添加了一些特殊标记，并已为您处理了所有与特殊标记相关的实现细节：\n",
    "\n",
    "- 在每个描述文本的开头和结尾分别添加一个特殊的 `<START>` 和 `<END>` 标记。\n",
    "- 罕见的单词会被替换为特殊的 `<UNK>` 标记（表示“未知”）。\n",
    "- 为了适应不同长度的描述文本，我们在 `<END>` 标记后为较短的描述文本添加特殊的 `<NULL>` 标记作为填充，并且不会对 `<NULL>` 标记计算损失或梯度。\n",
    "\n",
    "## 数据加载\n",
    "\n",
    "您可以使用文件 `mml/coco_utils.py` 中的函数 `load_coco_data` 加载所有 COCO 数据（描述文本、特征、URL 和词汇表）。运行以下代码单元即可加载数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Load COCO data from disk into a dictionary.\n",
    "# We'll work with dimensionality-reduced features for the remainder of this assignment,\n",
    "# but you can also experiment with the original features on your own by changing the flag below.\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "# Print out all the keys and values from the data dictionary.\n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查数据\n",
    "\n",
    "在处理数据之前，查看数据集中的示例总是一个好主意。\n",
    "\n",
    "您可以使用文件 `mml/coco_utils.py` 中的函数 `sample_coco_minibatch`，从 `load_coco_data` 返回的数据结构中采样小批量数据。运行以下代码以采样一小批训练数据并显示图像及其描述文本。多次运行并观察结果有助于更好地了解数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a minibatch and show the images and captions.\n",
    "# If you get an error, the URL just no longer exists, so don't worry!\n",
    "# You can re-sample as many times as you want.\n",
    "batch_size = 3\n",
    "\n",
    "captions, features, urls = sample_coco_minibatch(data, batch_size=batch_size)\n",
    "for i, (caption, url) in enumerate(zip(captions, urls)):\n",
    "    plt.imshow(image_from_url(url))\n",
    "    plt.axis('off')\n",
    "    caption_str = decode_captions(caption, data['idx_to_word'])\n",
    "    plt.title(caption_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "\n",
    "文件 `mml/rnn_layers.py` 包含循环神经网络所需的不同层类型的实现，而文件 `mml/classifiers/rnn.py` 则使用这些层实现了一个图像描述生成模型。\n",
    "\n",
    "我们将首先在 `mml/rnn_layers.py` 中实现不同类型的 RNN 层。\n",
    "\n",
    "## 注意事项\n",
    "\n",
    "- **长短期记忆网络（LSTM）：** LSTM 是经典 RNN 的常见变体。本作业的附加文件 `LSTM_Captioning.ipynb` 是一个可选的额外练习内容，您可以选择忽略与 LSTM 相关的内容（如 `mml/classifiers/rnn.py` 和 `mml/rnn_layers.py` 中的 LSTM 引用）。\n",
    "  \n",
    "### 下一步\n",
    "在 `mml/rnn_layers.py` 中实现标准的 RNN 层，并在模型中使用这些层为图像生成描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单步前向传播\n",
    "\n",
    "打开文件 `mml/rnn_layers.py`。该文件实现了循环神经网络中常用层的前向传播和反向传播。\n",
    "\n",
    "## 任务\n",
    "\n",
    "首先实现函数 `rnn_step_forward`，它负责实现 Vanilla RNN 在单个时间步的前向传播。该函数的签名如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H = 3, 10, 4\n",
    "\n",
    "x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.2, 0.4, num=H)\n",
    "\n",
    "next_h, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "expected_next_h = np.asarray([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN: Step Backward\n",
    "In the file `mml/rnn_layers.py` implement the `rnn_step_backward` function. After doing so run the following to numerically gradient check your implementation. You should see errors on the order of `e-8` or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mml.rnn_layers import rnn_step_forward, rnn_step_backward\n",
    "np.random.seed(231)\n",
    "N, D, H = 4, 5, 6\n",
    "x = np.random.randn(N, D)\n",
    "h = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn_step_forward(x, h, Wx, Wh, b)\n",
    "\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "fx = lambda x: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fh = lambda prev_h: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dnext_h)\n",
    "dprev_h_num = eval_numerical_gradient_array(fh, h, dnext_h)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dnext_h)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dnext_h)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dnext_h)\n",
    "\n",
    "dx, dprev_h, dWx, dWh, db = rnn_step_backward(dnext_h, cache)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dprev_h error: ', rel_error(dprev_h_num, dprev_h))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前向传播（整个序列）\n",
    "\n",
    "现在您已经完成了 Vanilla RNN 在单个时间步的前向传播和反向传播。接下来，我们需要将这些单步操作组合起来，实现一个可以处理完整数据序列的 RNN。\n",
    "\n",
    "## 任务\n",
    "\n",
    "在文件 `mml/rnn_layers.py` 中实现函数 `rnn_forward`。该函数将使用之前定义的 `rnn_step_forward` 来处理整个输入序列。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, D, H = 2, 3, 4, 5\n",
    "\n",
    "x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.7, 0.1, num=H)\n",
    "\n",
    "h, _ = rnn_forward(x, h0, Wx, Wh, b)\n",
    "expected_h = np.asarray([\n",
    "  [\n",
    "    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "  ],\n",
    "  [\n",
    "    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "print('h error: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播（整个序列）\n",
    "\n",
    "接下来，您需要实现 Vanilla RNN 对整个序列的反向传播。在文件 `mml/rnn_layers.py` 中完成函数 `rnn_backward` 的实现。该函数将调用之前实现的 `rnn_step_backward` 来完成对整个输入序列的反向传播。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 5\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "dx, dh0, dWx, dWh, db = rnn_backward(dout, cache)\n",
    "\n",
    "fx = lambda x: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dout)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding: 前向传播\n",
    "\n",
    "在深度学习系统中，我们通常用向量来表示单词。词汇表中的每个单词都会与一个向量相关联，这些向量会随着系统的其余部分一起被训练。\n",
    "\n",
    "在文件 `mml/rnn_layers.py` 中，您需要实现函数 `word_embedding_forward`，将单词（以整数表示）转换为向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, V, D = 2, 4, 5, 3\n",
    "\n",
    "x = np.asarray([[0, 3, 1, 2], [2, 1, 0, 3]])\n",
    "W = np.linspace(0, 1, num=V*D).reshape(V, D)\n",
    "\n",
    "out, _ = word_embedding_forward(x, W)\n",
    "expected_out = np.asarray([\n",
    " [[ 0.,          0.07142857,  0.14285714],\n",
    "  [ 0.64285714,  0.71428571,  0.78571429],\n",
    "  [ 0.21428571,  0.28571429,  0.35714286],\n",
    "  [ 0.42857143,  0.5,         0.57142857]],\n",
    " [[ 0.42857143,  0.5,         0.57142857],\n",
    "  [ 0.21428571,  0.28571429,  0.35714286],\n",
    "  [ 0.,          0.07142857,  0.14285714],\n",
    "  [ 0.64285714,  0.71428571,  0.78571429]]])\n",
    "\n",
    "print('out error: ', rel_error(expected_out, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding: 反向传播\n",
    "\n",
    "接下来，您需要在文件 `mml/rnn_layers.py` 中实现函数 `word_embedding_backward`，以完成单词嵌入的反向传播。该函数将计算嵌入矩阵的梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, T, V, D = 50, 3, 5, 6\n",
    "x = np.random.randint(V, size=(N, T))\n",
    "W = np.random.randn(V, D)\n",
    "\n",
    "out, cache = word_embedding_forward(x, W)\n",
    "dout = np.random.randn(*out.shape)\n",
    "dW = word_embedding_backward(dout, cache)\n",
    "\n",
    "f = lambda W: word_embedding_forward(x, W)[0]\n",
    "dW_num = eval_numerical_gradient_array(f, W, dout)\n",
    "\n",
    "print('dW error: ', rel_error(dW, dW_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Temporal Affine Layer\n",
    "\n",
    "在每个时间步，我们使用一个仿射函数将该时间步的 RNN 隐藏向量转换为词汇表中每个单词的得分。由于这与您在作业 2 中实现的仿射层非常相似，我们已经为您提供了函数 `temporal_affine_forward` 和 `temporal_affine_backward`，它们位于文件 `mml/rnn_layers.py` 中。\n",
    "\n",
    "## 检查代码\n",
    "\n",
    "运行以下代码对 `temporal_affine_forward` 和 `temporal_affine_backward` 的实现进行数值梯度检查。您应该看到误差在 \\(10^{-9}\\) 或更小范围内。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "# Gradient check for temporal affine layer\n",
    "N, T, D, M = 2, 3, 4, 5\n",
    "x = np.random.randn(N, T, D)\n",
    "w = np.random.randn(D, M)\n",
    "b = np.random.randn(M)\n",
    "\n",
    "out, cache = temporal_affine_forward(x, w, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "fx = lambda x: temporal_affine_forward(x, w, b)[0]\n",
    "fw = lambda w: temporal_affine_forward(x, w, b)[0]\n",
    "fb = lambda b: temporal_affine_forward(x, w, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dw_num = eval_numerical_gradient_array(fw, w, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "dx, dw, db = temporal_affine_backward(dout, cache)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Temporal Softmax Loss\n",
    "\n",
    "在 RNN 语言模型中，每个时间步都会生成词汇表中每个单词的得分。我们根据每个时间步的真实单词标签，使用 softmax 损失函数计算损失和梯度。损失在时间步上累加，并在小批量内取平均。\n",
    "\n",
    "## 特殊处理: `<NULL>` 标记\n",
    "\n",
    "由于我们在小批量中操作，不同的描述文本可能具有不同的长度。为了统一长度，我们在每个描述文本的末尾补充 `<NULL>` 标记。这些 `<NULL>` 标记不应该计入损失或梯度。\n",
    "\n",
    "因此，除了得分和真实标签之外，损失函数还接受一个 `mask` 数组，指示哪些得分计入损失。\n",
    "\n",
    "### 实现细节\n",
    "\n",
    "函数 `temporal_softmax_loss` 已为您实现，可以在文件 `mml/rnn_layers.py` 中查看其代码。接下来我们对该函数进行检查。\n",
    "\n",
    "### 检查代码\n",
    "\n",
    "运行以下代码对 `temporal_softmax_loss` 进行合理性检查和数值梯度检查。您应该看到 `dx` 的误差在 \\(10^{-7}\\) 或更小范围内。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check for temporal softmax loss\n",
    "from mml.rnn_layers import temporal_softmax_loss\n",
    "\n",
    "N, T, V = 100, 1, 10\n",
    "\n",
    "def check_loss(N, T, V, p):\n",
    "    x = 0.001 * np.random.randn(N, T, V)\n",
    "    y = np.random.randint(V, size=(N, T))\n",
    "    mask = np.random.rand(N, T) <= p\n",
    "    print(temporal_softmax_loss(x, y, mask)[0])\n",
    "  \n",
    "check_loss(100, 1, 10, 1.0)   # Should be about 2.3\n",
    "check_loss(100, 10, 10, 1.0)  # Should be about 23\n",
    "check_loss(5000, 10, 10, 0.1) # Should be within 2.2-2.4\n",
    "\n",
    "# Gradient check for temporal softmax loss\n",
    "N, T, V = 7, 8, 9\n",
    "\n",
    "x = np.random.randn(N, T, V)\n",
    "y = np.random.randint(V, size=(N, T))\n",
    "mask = (np.random.rand(N, T) > 0.5)\n",
    "\n",
    "loss, dx = temporal_softmax_loss(x, y, mask, verbose=False)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: temporal_softmax_loss(x, y, mask)[0], x, verbose=False)\n",
    "\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Image Captioning\n",
    "\n",
    "现在您已经实现了所需的各个层，接下来可以将它们组合起来构建一个图像描述生成模型。打开文件 `mml/classifiers/rnn.py`，查看 `CaptioningRNN` 类。\n",
    "\n",
    "在 `loss` 函数中实现模型的前向和反向传播。目前您只需要实现 `cell_type='rnn'`（Vanilla RNN）的情况；稍后您将实现 LSTM 的逻辑。\n",
    "\n",
    "完成后，运行以下代码以使用一个小测试用例检查您的前向传播实现。您应该看到误差在 \\(10^{-10}\\) 或更小范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "V = len(word_to_idx)\n",
    "T = 13\n",
    "\n",
    "model = CaptioningRNN(\n",
    "    word_to_idx,\n",
    "    input_dim=D,\n",
    "    wordvec_dim=W,\n",
    "    hidden_dim=H,\n",
    "    cell_type='rnn',\n",
    "    dtype=np.float64\n",
    ")\n",
    "\n",
    "# Set all model parameters to fixed values\n",
    "for k, v in model.params.items():\n",
    "    model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n",
    "\n",
    "features = np.linspace(-1.5, 0.3, num=(N * D)).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T)\n",
    "\n",
    "loss, grads = model.loss(features, captions)\n",
    "expected_loss = 9.83235591003\n",
    "\n",
    "print('loss: ', loss)\n",
    "print('expected loss: ', expected_loss)\n",
    "print('difference: ', abs(loss - expected_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元以对 CaptioningRNN 类执行数值梯度检查；你应该看到误差在 e-6 量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "batch_size = 2\n",
    "timesteps = 3\n",
    "input_dim = 4\n",
    "wordvec_dim = 5\n",
    "hidden_dim = 6\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "captions = np.random.randint(vocab_size, size=(batch_size, timesteps))\n",
    "features = np.random.randn(batch_size, input_dim)\n",
    "\n",
    "model = CaptioningRNN(\n",
    "    word_to_idx,\n",
    "    input_dim=input_dim,\n",
    "    wordvec_dim=wordvec_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    cell_type='rnn',\n",
    "    dtype=np.float64,\n",
    ")\n",
    "\n",
    "loss, grads = model.loss(features, captions)\n",
    "\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(features, captions)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s relative error: %e' % (param_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在小数据集上过拟合 RNN 描述生成模型\n",
    "\n",
    "在本次作业中，我们使用 `CaptioningSolver` 类来训练图像描述生成模型。打开文件 `mml/captioning_solver.py`，阅读 `CaptioningSolver` 类\n",
    "\n",
    "熟悉该 API 后，运行以下代码以确保你的模型能在 100 个训练样本的小数据集上过拟合。你应该看到最终的损失小于 0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "small_data = load_coco_data(max_train=50)\n",
    "\n",
    "small_rnn_model = CaptioningRNN(\n",
    "    cell_type='rnn',\n",
    "    word_to_idx=data['word_to_idx'],\n",
    "    input_dim=data['train_features'].shape[1],\n",
    "    hidden_dim=512,\n",
    "    wordvec_dim=256,\n",
    ")\n",
    "\n",
    "small_rnn_solver = CaptioningSolver(\n",
    "    small_rnn_model, small_data,\n",
    "    update_rule='adam',\n",
    "    num_epochs=50,\n",
    "    batch_size=25,\n",
    "    optim_config={\n",
    "     'learning_rate': 5e-3,\n",
    "    },\n",
    "    lr_decay=0.95,\n",
    "    verbose=True, print_every=10,\n",
    ")\n",
    "\n",
    "small_rnn_solver.train()\n",
    "\n",
    "# Plot the training losses.\n",
    "plt.plot(small_rnn_solver.loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印最终的训练损失。你应该看到最终的损失小于 0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "test": "rnn_final_training_loss"
   },
   "outputs": [],
   "source": [
    "print('Final loss: ', small_rnn_solver.loss_history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试时的 RNN 采样\n",
    "\n",
    "与分类模型不同，图像描述生成模型在训练时和测试时的行为差异很大。在训练时，我们可以使用真实的描述文本（ground-truth caption），因此在每个时间步将真实的单词作为输入提供给 RNN。在测试时，我们从词汇表的分布中采样每个时间步的输出，并将该采样结果作为下一时间步的 RNN 输入。\n",
    "\n",
    "在文件 `mml/classifiers/rnn.py` 中实现测试时的 `sample` 方法。完成后，运行以下代码以在训练数据和验证数据上从你的过拟合模型中采样。训练数据上的采样结果应该非常好。然而，验证数据上的采样结果可能不会很合理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If you get an error, the URL just no longer exists, so don't worry!\n",
    "# You can re-sample as many times as you want.\n",
    "for split in ['train', 'val']:\n",
    "    minibatch = sample_coco_minibatch(small_data, split=split, batch_size=2)\n",
    "    gt_captions, features, urls = minibatch\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    sample_captions = small_rnn_model.sample(features)\n",
    "    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "        img = image_from_url(url)\n",
    "        # Skip missing URLs.\n",
    "        if img is None: continue\n",
    "        plt.imshow(img)          \n",
    "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
